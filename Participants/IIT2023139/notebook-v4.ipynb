{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9277757,"sourceType":"datasetVersion","datasetId":5440100}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CNN From Scratch for Image Classification\n### Issue #134 – Forget Accuracy, Try from Scratch\n\nThis notebook implements a Convolutional Neural Network (CNN) **from scratch**\nfor image classification using PyTorch.\n\nThe workflow connects previous issues by:\n- Reusing dataset organization (train / test / eval)\n- Training a CNN from random initialization\n- Avoiding all pretrained models\n\nThe focus is on understanding CNN fundamentals rather than achieving high accuracy.\n","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport shutil\nfrom pathlib import Path\nfrom PIL import Image\nfrom PIL import UnidentifiedImageError\ntorch.backends.cudnn.benchmark = True\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T09:37:56.887840Z","iopub.execute_input":"2026-01-09T09:37:56.888433Z","iopub.status.idle":"2026-01-09T09:37:56.893502Z","shell.execute_reply.started":"2026-01-09T09:37:56.888401Z","shell.execute_reply":"2026-01-09T09:37:56.892757Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nif torch.cuda.is_available():\n    print(\"GPU is enabled\")\n    print(\"Device name:\", torch.cuda.get_device_name(0))\n    print(\"Number of GPUs:\", torch.cuda.device_count())\nelse:\n    print(\"Running on CPU\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T07:41:07.024768Z","iopub.execute_input":"2026-01-09T07:41:07.025174Z","iopub.status.idle":"2026-01-09T07:41:07.039049Z","shell.execute_reply.started":"2026-01-09T07:41:07.025151Z","shell.execute_reply":"2026-01-09T07:41:07.038329Z"}},"outputs":[{"name":"stdout","text":"GPU is enabled\nDevice name: Tesla P100-PCIE-16GB\nNumber of GPUs: 1\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"def safe_pil_loader(path):\n    try:\n        with open(path, \"rb\") as f:\n            img = Image.open(f)\n            img = img.convert(\"RGB\")\n            return img\n    except (UnidentifiedImageError, OSError, ValueError):\n        return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T07:41:07.040282Z","iopub.execute_input":"2026-01-09T07:41:07.040729Z","iopub.status.idle":"2026-01-09T07:41:07.055252Z","shell.execute_reply.started":"2026-01-09T07:41:07.040707Z","shell.execute_reply":"2026-01-09T07:41:07.054558Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\n\nclass SafeImageFolder(ImageFolder):\n    def __getitem__(self, index):\n        path, target = self.samples[index]\n        sample = safe_pil_loader(path)\n\n        if sample is None:\n            raise RuntimeError(f\"Corrupted image slipped through filter: {path}\")\n\n        if self.transform is not None:\n            sample = self.transform(sample)\n\n        return sample, target\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T07:41:07.055920Z","iopub.execute_input":"2026-01-09T07:41:07.056130Z","iopub.status.idle":"2026-01-09T07:41:07.064192Z","shell.execute_reply.started":"2026-01-09T07:41:07.056110Z","shell.execute_reply":"2026-01-09T07:41:07.063497Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"## **Dataset Sanitization**","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef filter_corrupted_samples(image_folder):\n    \"\"\"\n    Removes corrupted image paths from ImageFolder.samples\n    \"\"\"\n    valid_samples = []\n    corrupted = 0\n\n    for path, label in tqdm(image_folder.samples, desc=\"Filtering corrupted images\"):\n        try:\n            with open(path, \"rb\") as f:\n                img = Image.open(f)\n                img.verify()  # quick integrity check\n            valid_samples.append((path, label))\n        except Exception:\n            corrupted += 1\n\n    image_folder.samples = valid_samples\n    image_folder.targets = [label for _, label in valid_samples]\n\n    print(f\"Removed {corrupted} corrupted images.\")\n    print(f\"Remaining valid images: {len(valid_samples)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T07:41:07.065548Z","iopub.execute_input":"2026-01-09T07:41:07.065757Z","iopub.status.idle":"2026-01-09T07:41:07.079751Z","shell.execute_reply.started":"2026-01-09T07:41:07.065737Z","shell.execute_reply":"2026-01-09T07:41:07.079052Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"## Dataset Splitter Class","metadata":{}},{"cell_type":"code","source":"class DatasetSplitter:\n    def __init__(self, source_dir, output_dir, split_ratio=(0.7, 0.2, 0.1), seed=42):\n        self.source_dir = Path(source_dir)\n        self.output_dir = Path(output_dir)\n        self.train_ratio, self.test_ratio, self.eval_ratio = split_ratio\n        self.seed = seed\n        random.seed(self.seed)\n\n    def _create_dirs(self, classes):\n        for split in [\"train\", \"test\", \"eval\"]:\n            for cls in classes:\n                (self.output_dir / split / cls).mkdir(parents=True, exist_ok=True)\n\n    def split(self):\n        classes = [d.name for d in self.source_dir.iterdir() if d.is_dir()]\n        self._create_dirs(classes)\n\n        for cls in classes:\n            images = list((self.source_dir / cls).glob(\"*\"))\n            random.shuffle(images)\n\n            total = len(images)\n            train_end = int(self.train_ratio * total)\n            test_end = train_end + int(self.test_ratio * total)\n\n            splits = {\n                \"train\": images[:train_end],\n                \"test\": images[train_end:test_end],\n                \"eval\": images[test_end:]\n            }\n\n            for split, files in splits.items():\n                for file in files:\n                    target = self.output_dir / split / cls / file.name\n                    if not target.exists():\n                        os.symlink(file, target)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T07:41:07.080570Z","iopub.execute_input":"2026-01-09T07:41:07.080869Z","iopub.status.idle":"2026-01-09T07:41:07.096389Z","shell.execute_reply.started":"2026-01-09T07:41:07.080835Z","shell.execute_reply":"2026-01-09T07:41:07.095810Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"SOURCE_DATASET_PATH = \"/kaggle/input/spacenet-an-optimally-distributed-astronomy-data/SpaceNet.FLARE.imam_alam\"\nOUTPUT_DATASET_PATH = \"/kaggle/working/dataset\"\n\nsplitter = DatasetSplitter(\n    source_dir=SOURCE_DATASET_PATH,\n    output_dir=OUTPUT_DATASET_PATH,\n    split_ratio=(0.7, 0.2, 0.1)\n)\n\nsplitter.split()\n\nprint(\"Dataset successfully split into train / test / eval directories.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T07:41:07.097285Z","iopub.execute_input":"2026-01-09T07:41:07.097739Z","iopub.status.idle":"2026-01-09T07:41:08.852470Z","shell.execute_reply.started":"2026-01-09T07:41:07.097703Z","shell.execute_reply":"2026-01-09T07:41:08.851744Z"}},"outputs":[{"name":"stdout","text":"Dataset successfully split into train / test / eval directories.\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"DATASET_DIR = \"/kaggle/working/dataset\"\n\nrequired_dirs = [\"train\", \"test\", \"eval\"]\nfor d in required_dirs:\n    path = os.path.join(DATASET_DIR, d)\n    assert os.path.exists(path), f\"Missing directory: {path}\"\n\nprint(\"Dataset split verified: train / test / eval present\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T07:41:08.853431Z","iopub.execute_input":"2026-01-09T07:41:08.853725Z","iopub.status.idle":"2026-01-09T07:41:08.858282Z","shell.execute_reply.started":"2026-01-09T07:41:08.853692Z","shell.execute_reply":"2026-01-09T07:41:08.857604Z"}},"outputs":[{"name":"stdout","text":"Dataset split verified: train / test / eval present\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"## Dataset Loading and Preprocessing\n\nImages are resized and converted to tensors before being passed into the CNN.\nNo normalization is applied to keep preprocessing minimal and educational.\n","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 64\nIMG_SIZE = 128\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n                         std=[0.5, 0.5, 0.5])\n])\n\n# ---- Datasets ----\ntrain_dataset = SafeImageFolder(\n    root=os.path.join(DATASET_DIR, \"train\"),\n    transform=train_transform\n)\nfilter_corrupted_samples(train_dataset)\n\nval_dataset = SafeImageFolder(\n    root=os.path.join(DATASET_DIR, \"eval\"),\n    transform=train_transform\n)\nfilter_corrupted_samples(val_dataset)\n\ntest_dataset = SafeImageFolder(\n    root=os.path.join(DATASET_DIR, \"test\"),\n    transform=train_transform\n)\nfilter_corrupted_samples(test_dataset)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=torch.cuda.is_available()\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=0,\n    pin_memory=torch.cuda.is_available()\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=0,\n    pin_memory=torch.cuda.is_available()\n)\n\n# ---- Metadata ----\nnum_classes = len(train_dataset.classes)\nprint(\"Detected Classes:\", train_dataset.classes)\nprint(\"Number of classes:\", num_classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T09:38:06.572734Z","iopub.execute_input":"2026-01-09T09:38:06.573053Z","iopub.status.idle":"2026-01-09T09:42:47.353688Z","shell.execute_reply.started":"2026-01-09T09:38:06.573020Z","shell.execute_reply":"2026-01-09T09:42:47.353033Z"}},"outputs":[{"name":"stderr","text":"Filtering corrupted images: 100%|██████████| 8974/8974 [02:34<00:00, 58.13it/s]  \n","output_type":"stream"},{"name":"stdout","text":"Removed 960 corrupted images.\nRemaining valid images: 8014\n","output_type":"stream"},{"name":"stderr","text":"Filtering corrupted images: 100%|██████████| 1289/1289 [00:37<00:00, 34.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Removed 143 corrupted images.\nRemaining valid images: 1146\n","output_type":"stream"},{"name":"stderr","text":"Filtering corrupted images: 100%|██████████| 2561/2561 [01:14<00:00, 34.29it/s] ","output_type":"stream"},{"name":"stdout","text":"Removed 273 corrupted images.\nRemaining valid images: 2288\nDetected Classes: ['asteroid', 'black hole', 'comet', 'constellation', 'galaxy', 'nebula', 'planet', 'star']\nNumber of classes: 8\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"## CNN Architecture (Built From Scratch)\n\nA simple CNN architecture is implemented using:\n- Convolution layers\n- ReLU activations\n- Max pooling\n- Fully connected layers\n\nNo pretrained networks are used.\n","metadata":{}},{"cell_type":"code","source":"class SimpleCNN(nn.Module):\n    def __init__(self, num_classes):\n        super(SimpleCNN, self).__init__()\n\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(128 * (IMG_SIZE // 8) * (IMG_SIZE // 8), 256),\n            nn.ReLU(),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T09:42:56.090455Z","iopub.execute_input":"2026-01-09T09:42:56.091063Z","iopub.status.idle":"2026-01-09T09:42:56.099163Z","shell.execute_reply.started":"2026-01-09T09:42:56.091029Z","shell.execute_reply":"2026-01-09T09:42:56.098462Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"model = SimpleCNN(num_classes).to(device)\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T07:48:05.632533Z","iopub.execute_input":"2026-01-09T07:48:05.632754Z","iopub.status.idle":"2026-01-09T07:48:05.890074Z","shell.execute_reply.started":"2026-01-09T07:48:05.632733Z","shell.execute_reply":"2026-01-09T07:48:05.889449Z"}},"outputs":[{"name":"stdout","text":"SimpleCNN(\n  (features): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): ReLU()\n    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU()\n    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=32768, out_features=256, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=256, out_features=8, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"## Loss Function and Optimizer\n\nCross-entropy loss is used for multi-class classification.\nThe Adam optimizer is used to train the network.\n","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T09:42:58.745918Z","iopub.execute_input":"2026-01-09T09:42:58.746462Z","iopub.status.idle":"2026-01-09T09:42:58.751953Z","shell.execute_reply.started":"2026-01-09T09:42:58.746433Z","shell.execute_reply":"2026-01-09T09:42:58.751236Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"model = model.to(device)\ncriterion = criterion.to(device)\n\nprint(\"Model parameters on:\", next(model.parameters()).device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T09:43:01.162266Z","iopub.execute_input":"2026-01-09T09:43:01.162847Z","iopub.status.idle":"2026-01-09T09:43:01.170403Z","shell.execute_reply.started":"2026-01-09T09:43:01.162821Z","shell.execute_reply":"2026-01-09T09:43:01.169677Z"}},"outputs":[{"name":"stdout","text":"Model parameters on: cuda:0\n","output_type":"stream"}],"execution_count":51},{"cell_type":"markdown","source":"## Model Training\n\nThe CNN is trained from random initialization using the training dataset.\n","metadata":{}},{"cell_type":"code","source":"import time\n\nEPOCHS = 5\ntotal_start_time = time.time()\n\nfor epoch in range(EPOCHS):\n    print(f\">>> Starting Epoch {epoch+1}\")\n    epoch_start_time = time.time()\n\n    model.train()\n    running_loss = 0.0\n\n    for images, labels in train_loader:\n        images = images.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n\n        optimizer.zero_grad(set_to_none=True)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    if device.type == \"cuda\":\n        torch.cuda.synchronize()\n\n    epoch_time = time.time() - epoch_start_time\n    avg_loss = running_loss / len(train_loader)\n\n    print(\n        f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n        f\"Loss: {avg_loss:.4f} | \"\n        f\"Time: {epoch_time:.2f}s\"\n    )\n\ntotal_time = time.time() - total_start_time\nprint(f\"\\nTotal Training Time: {total_time:.2f}s\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T09:43:04.156891Z","iopub.execute_input":"2026-01-09T09:43:04.157689Z","iopub.status.idle":"2026-01-09T10:31:03.577813Z","shell.execute_reply.started":"2026-01-09T09:43:04.157657Z","shell.execute_reply":"2026-01-09T10:31:03.575856Z"}},"outputs":[{"name":"stdout","text":">>> Starting Epoch 1\nEpoch [1/5] | Loss: 0.2161 | Time: 563.33s\n>>> Starting Epoch 2\nEpoch [2/5] | Loss: 0.1541 | Time: 619.99s\n>>> Starting Epoch 3\nEpoch [3/5] | Loss: 0.1390 | Time: 572.46s\n>>> Starting Epoch 4\nEpoch [4/5] | Loss: 0.1252 | Time: 558.03s\n>>> Starting Epoch 5\nEpoch [5/5] | Loss: 0.1255 | Time: 565.60s\n\nTotal Training Time: 2879.41s\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"## Validation Evaluation\n","metadata":{}},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nval_accuracy = 100 * correct / total\nprint(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:31:03.581708Z","iopub.execute_input":"2026-01-09T10:31:03.581964Z","iopub.status.idle":"2026-01-09T10:33:46.388649Z","shell.execute_reply.started":"2026-01-09T10:31:03.581935Z","shell.execute_reply":"2026-01-09T10:33:46.387909Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 58.29%\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"## Test Evaluation\n","metadata":{}},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\ntest_accuracy = 100 * correct / total\nprint(f\"Test Accuracy: {test_accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-09T10:33:46.390505Z","iopub.execute_input":"2026-01-09T10:33:46.390745Z","iopub.status.idle":"2026-01-09T10:39:13.999241Z","shell.execute_reply.started":"2026-01-09T10:33:46.390721Z","shell.execute_reply":"2026-01-09T10:39:13.998577Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 58.87%\n","output_type":"stream"}],"execution_count":54},{"cell_type":"markdown","source":"## Summary\n\nIn this notebook, a Convolutional Neural Network was implemented and trained\nentirely from scratch using PyTorch. The model was trained from random\ninitialization and evaluated on validation and test datasets.\n\nThis task focuses on understanding CNN internals rather than maximizing accuracy,\nas required by Issue #134.\n","metadata":{}}]}